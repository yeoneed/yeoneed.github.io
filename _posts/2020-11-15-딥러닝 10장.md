---
layout: post
title: 딥러닝 10장 정리
subtitle: 
comments: true
tags: [software]
---


## 딥러닝 10장 정리

### 과제 위주로 정리해보기
- [x] <strong>back propagation</strong> 역전파: MLP를 학습시키는 방법
-> <strong>문제:</strong> Back propagation(역전파)에서는 기울기 소실 문제가 발생 할 수 있다.(sigmoid(v)e)
=> 이는 활성화 함수를 잘 선택함으로써 해결한다. 
- [x] <strong>Dropout</strong>: 신경망 모델이 복잡해질 때 가중치 감소만으로는 어려운데 드롭아웃 기법은 뉴런의 연결을 임의로 삭제하는 것이다. 훈련할 때 임의의 뉴런을 골라 삭제하여 신호를 전달하지 않게 한다. 테스트할 때는 모든 뉴런을 사용한다.
- [x] <strong>Weight decay</strong>: 기존 가중치를 갱신할 때 마다 0과 1 사이의 값을 가지는 가중치 e를 곱함으로써 학습을 방해하는 대신 과적합을 방지하는 방법

